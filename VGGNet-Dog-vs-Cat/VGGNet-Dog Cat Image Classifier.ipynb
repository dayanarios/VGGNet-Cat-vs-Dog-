{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog vs. Cat Image Classifier using VGGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = \"/Users/dayanarios/Education/MachineLearning/HW/VGGNet-Dog-vs-Cat/data/train/\"\n",
    "TEST_DATA_DIR = \"/Users/dayanarios/Education/MachineLearning/HW/VGGNet-Dog-vs-Cat/data/test1/\"\n",
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN_DATA_DIR and TEST_DATA_DIR contain the path to the training and testing data directories respectively. Both training and testing datasets where obtained from [Kaggle's Dog vs Cats 2013 Competition](https://www.kaggle.com/c/dogs-vs-cats/data). The original set contains 25,000 training images and 12,500 testing images. It should be noted the training set was split into 80% training and 20% validation. \n",
    "\n",
    "IMG_WIDTH and IMG_HEIGHT contained the fixed dimension for image width and height respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in our dataset follows the notation cat.x.jpg or dog.x.jpg where x is some integer between 0 and 12,499, inclusive. Images must be preprocessed and formatted in order to facilitate training and testing. Cat images are labeled as 0 and dog images as 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(label):  \n",
    "    if label == 'cat':\n",
    "        return 0\n",
    "    elif label == 'dog':\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label_img method takes and a string as an argument and compares it with the strings 'cat' and 'dog'. Each cat image is assigned the label 0 and each dog image is assigned 1. If the string passed to this method contains a label that differs from our given notation, the label_img function returns -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data():\n",
    "    training_data = []\n",
    "    for img in os.listdir(TRAIN_DATA_DIR):\n",
    "        if img.endswith(\".jpg\"):\n",
    "            path = os.path.join(TRAIN_DATA_DIR, img)\n",
    "            label, _id, _ = img.split(\".\", 2)\n",
    "            label_code = label_img(label)\n",
    "            img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (IMG_WIDTH,IMG_HEIGHT))\n",
    "            training_data.append((label_code, img, _id))\n",
    "    \n",
    "    training_data = np.array(training_data)\n",
    "    #np.save('training_data', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our program takes the file name of each image and assigns a label to it. training_data will contain all the information necessary for training our classifier. Line 3 iterates through the given directory and stores the fliename in img. To ensure we observe only .jpg files each filename's extension is compared with the desired extension. The filename is then split at each \".\" and stored in their respective variables. Label contains the type of image, namely 'cat' or 'dog', while \\_id contains the image's assigned id. The extension of the filename is placed in the throwaway variable '_'. \n",
    "\n",
    "The images label is passed to the label_img method which returns 0 for a cat image and 1 for a dog image. \n",
    "\n",
    "The VGGNet model assumes inputs are square images. To ensure there are no discrepancies between picture dimensions all images are resized to 150 x 150. The cv2 package handles all image processing. cv2.imread(path,cv2.IMREAD_COLOR) reads the image found at the given image path, the second arguments how the image should be processed. In the contents of this project we want images to retain their color properties thus we use cv2.IMREAD_COLOR. (It should be noted that cv2 uses BGR instead of RGB as the default color ordering)\n",
    "\n",
    "training_data array will contain all the data for training. Each element will consist of a tuple containing the assigned label code and an img object. training_data is converted into a numpy array in order to faciliate linear algebra operations involved in VGGNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(data, n):\n",
    "    #data = np.load('training_data.npy', allow_pickle=True)\n",
    "    image = data[n][1]\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display_image displays the $n^{th}$ image in the given training dataset. This function is used to ensure the data from prepare_training_data() was properly processed using the cv2 package. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing Test Data\n",
    "Testing data has the format x.jpg where x is an integer between 1 and 12,500. Each image must be accurately classified as either a dog or cat image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_testing_data():\n",
    "    testing_data = []\n",
    "    for img in os.listdir(TEST_DATA_DIR):\n",
    "        if img.endswith(\".jpg\"):\n",
    "            path = os.path.join(TEST_DATA_DIR, img)\n",
    "            print(path)\n",
    "            _id, _ = img.split(\".\", 1)\n",
    "            print(_id)\n",
    "            img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (IMG_WIDTH,IMG_HEIGHT))\n",
    "            testing_data.append((img, _id))\n",
    "    \n",
    "    #cv2.imshow(\"test\", img)\n",
    "    #cv2.waitKey(25)\n",
    "    #cv2.destroyAllWindows()\n",
    "    testing_data = np.array(testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Data Needs to be prepared in a similar fashion to training data. All images are read using the cv2 package, resized accordingly, and appended to our testing data set, testing_data. Each entry is stored in a tuple with two elements, the first contains the img object and the second the image id, extracted from the image's filename. testing_data is converted to a numpy array for later linear algebra calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNET Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGNet Architecture with 16 layers will be implemented using Keras with Tensorflow running in the backend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    prepare_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dogcatclassifier",
   "language": "python",
   "name": "dogcatclassifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
